{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - pandas (Seth Romero)  \n",
    "### due 11/17/2022   \n",
    "\n",
    "Use this notebook and prompts to complete the homework. Throughout there will be hints and some code provided  \n",
    "\n",
    "### Things you will need:  \n",
    "- Install os, NumPy, pandas  \n",
    "- states_covid.csv  \n",
    "- Bloom_etal_2018_Reduced_Dataset.csv  \n",
    "- logfiles.tgz (or some other multiple file dataset)  \n",
    "\n",
    "*NOTE*: Make sure your PATH is correct  \n",
    "\n",
    "**import packages & check required datasets**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/mnt/c/Users/Seth/Documents/GitHub/F22_BIOL792_coursepage/week11_python6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(os.path.join(PATH,'states_covid.csv')), 'states_covid.csv does not exist' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(os.path.join(PATH,'Bloom_etal_2018_Reduced_Dataset.csv')), 'Bloom_etal_2018_Reduced_Dataset.csv does not exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - DataFrame manipulation  \n",
    "\n",
    "Using **states_covid.csv**, we are going to read the data in as a DataFrame to manipulate, subset, and filter in various ways.   \n",
    "\n",
    "### Task 1.1 \n",
    "\n",
    "Read in states_covid.csv with date as a \"date\" dtype, and only columns consisting of the hospitalization (4 col), ICU (2 col), and Ventilators (2 col)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                      datetime64[ns]\n",
       "state                             object\n",
       "hospitalized                     float64\n",
       "hospitalizedCumulative           float64\n",
       "hospitalizedCurrently            float64\n",
       "hospitalizedIncrease               int64\n",
       "inIcuCumulative                  float64\n",
       "inIcuCurrently                   float64\n",
       "onVentilatorCumulative           float64\n",
       "onVentilatorCurrently            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_opts = ['hosp', 'icu', 'vent', 'date', 'state']\n",
    "sub_col = lambda x: any(name in x.casefold() for name in col_opts)\n",
    "covid_states_df = pd.read_csv('states_covid.csv',\n",
    "                             usecols = sub_col,\n",
    "                             parse_dates = ['date'])\n",
    "covid_states_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>hospitalized</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AK</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AL</td>\n",
       "      <td>45250.0</td>\n",
       "      <td>45250.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>122</td>\n",
       "      <td>2632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AR</td>\n",
       "      <td>14617.0</td>\n",
       "      <td>14617.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>AZ</td>\n",
       "      <td>57072.0</td>\n",
       "      <td>57072.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date state  hospitalized  hospitalizedCumulative  \\\n",
       "0 2021-02-23    AK        1260.0                  1260.0   \n",
       "1 2021-02-23    AL       45250.0                 45250.0   \n",
       "2 2021-02-23    AR       14617.0                 14617.0   \n",
       "3 2021-02-23    AS           NaN                     NaN   \n",
       "4 2021-02-23    AZ       57072.0                 57072.0   \n",
       "\n",
       "   hospitalizedCurrently  hospitalizedIncrease  inIcuCumulative  \\\n",
       "0                   38.0                     9              NaN   \n",
       "1                  762.0                   122           2632.0   \n",
       "2                  545.0                    47              NaN   \n",
       "3                    NaN                     0              NaN   \n",
       "4                 1515.0                    78              NaN   \n",
       "\n",
       "   inIcuCurrently  onVentilatorCumulative  onVentilatorCurrently  \n",
       "0             NaN                     NaN                    5.0  \n",
       "1             NaN                  1497.0                    NaN  \n",
       "2           204.0                  1505.0                   99.0  \n",
       "3             NaN                     NaN                    NaN  \n",
       "4           447.0                     NaN                  266.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_states_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 \n",
    "\n",
    "For each of the following catergories: *currently* hospitalized, *currently* in the ICU, and *currently* on ventilation...  \n",
    "Find the 5 states with the greatest numbers in each catergory and list them in decreasing order.      \n",
    "*hint*: sort_values, unique  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>CA</td>\n",
       "      <td>22851.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17733</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>NY</td>\n",
       "      <td>18825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>TX</td>\n",
       "      <td>14218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12162</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>FL</td>\n",
       "      <td>9520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17618</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8270.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date state  hospitalizedCurrently\n",
       "2637  2021-01-07    CA                22851.0\n",
       "17733 2020-04-13    NY                18825.0\n",
       "2399  2021-01-12    TX                14218.0\n",
       "12162 2020-07-21    FL                 9520.0\n",
       "17618 2020-04-15    NJ                 8270.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top5(df, col, group):\n",
    "    return df.sort_values(by=col, ascending=False).drop_duplicates(subset=group)[['date', group, col]].head(5)\n",
    "    \n",
    "top5(covid_states_df, 'hospitalizedCurrently', 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17677</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>NY</td>\n",
       "      <td>5225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>CA</td>\n",
       "      <td>4971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>TX</td>\n",
       "      <td>3686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17674</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17888</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>MI</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date state  inIcuCurrently\n",
       "17677 2020-04-14    NY          5225.0\n",
       "2413  2021-01-11    CA          4971.0\n",
       "1951  2021-01-20    TX          3686.0\n",
       "17674 2020-04-14    NJ          2051.0\n",
       "17888 2020-04-10    MI          1663.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5(covid_states_df, 'inIcuCurrently', 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16389</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>NY</td>\n",
       "      <td>2425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17618</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17832</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>MI</td>\n",
       "      <td>1441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>OH</td>\n",
       "      <td>863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>IL</td>\n",
       "      <td>821.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date state  onVentilatorCurrently\n",
       "16389 2020-05-07    NY                 2425.0\n",
       "17618 2020-04-15    NJ                 1705.0\n",
       "17832 2020-04-11    MI                 1441.0\n",
       "3958  2020-12-15    OH                  863.0\n",
       "17768 2020-04-12    IL                  821.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5(covid_states_df, 'onVentilatorCurrently', 'state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 \n",
    "\n",
    "For each state, identify the date when the state reached 1000 cumulative hospitilized covid patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NY</td>\n",
       "      <td>2020-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FL</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GA</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OH</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PA</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MA</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MD</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CO</td>\n",
       "      <td>2020-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ</td>\n",
       "      <td>2020-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WI</td>\n",
       "      <td>2020-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>VA</td>\n",
       "      <td>2020-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KY</td>\n",
       "      <td>2020-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MS</td>\n",
       "      <td>2020-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TN</td>\n",
       "      <td>2020-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SC</td>\n",
       "      <td>2020-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MN</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RI</td>\n",
       "      <td>2020-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IN</td>\n",
       "      <td>2020-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NM</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>WA</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NJ</td>\n",
       "      <td>2020-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OK</td>\n",
       "      <td>2020-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NE</td>\n",
       "      <td>2020-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UT</td>\n",
       "      <td>2020-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>2020-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KS</td>\n",
       "      <td>2020-06-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>OR</td>\n",
       "      <td>2020-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID</td>\n",
       "      <td>2020-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SD</td>\n",
       "      <td>2020-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ND</td>\n",
       "      <td>2020-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MT</td>\n",
       "      <td>2020-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HI</td>\n",
       "      <td>2020-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>WY</td>\n",
       "      <td>2020-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ME</td>\n",
       "      <td>2020-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NH</td>\n",
       "      <td>2021-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DC</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GU</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IA</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IL</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LA</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MI</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MO</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MP</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NC</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NV</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PR</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TX</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VI</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>WV</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state       date\n",
       "37    NY 2020-03-21\n",
       "10    FL 2020-04-02\n",
       "11    GA 2020-04-02\n",
       "38    OH 2020-04-04\n",
       "41    PA 2020-04-04\n",
       "21    MA 2020-04-04\n",
       "22    MD 2020-04-06\n",
       "6     CO 2020-04-07\n",
       "4     AZ 2020-04-11\n",
       "53    WI 2020-04-14\n",
       "49    VA 2020-04-16\n",
       "19    KY 2020-04-18\n",
       "28    MS 2020-04-26\n",
       "46    TN 2020-04-29\n",
       "44    SC 2020-04-29\n",
       "25    MN 2020-04-30\n",
       "7     CT 2020-05-01\n",
       "1     AL 2020-05-01\n",
       "43    RI 2020-05-03\n",
       "17    IN 2020-05-08\n",
       "35    NM 2020-05-20\n",
       "52    WA 2020-05-21\n",
       "34    NJ 2020-05-26\n",
       "39    OK 2020-06-03\n",
       "32    NE 2020-06-11\n",
       "48    UT 2020-06-13\n",
       "2     AR 2020-06-15\n",
       "18    KS 2020-06-17\n",
       "40    OR 2020-06-25\n",
       "15    ID 2020-08-11\n",
       "45    SD 2020-08-29\n",
       "31    ND 2020-10-08\n",
       "29    MT 2020-10-17\n",
       "13    HI 2020-10-18\n",
       "55    WY 2020-12-18\n",
       "23    ME 2020-12-23\n",
       "0     AK 2020-12-29\n",
       "33    NH 2021-01-24\n",
       "3     AS        NaT\n",
       "5     CA        NaT\n",
       "8     DC        NaT\n",
       "9     DE        NaT\n",
       "12    GU        NaT\n",
       "14    IA        NaT\n",
       "16    IL        NaT\n",
       "20    LA        NaT\n",
       "24    MI        NaT\n",
       "26    MO        NaT\n",
       "27    MP        NaT\n",
       "30    NC        NaT\n",
       "36    NV        NaT\n",
       "42    PR        NaT\n",
       "47    TX        NaT\n",
       "50    VI        NaT\n",
       "51    VT        NaT\n",
       "54    WV        NaT"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some states don't have a record of cumulative hospitalization, date of threshold may be before date of record or just unknown...\n",
    "hosp1000_w_value = covid_states_df[covid_states_df.hospitalizedCumulative >= 1000]\n",
    "w_value = hosp1000_w_value.sort_values(by='date', ascending=True).drop_duplicates(subset='state').sort_values(by='state', ascending=True)\n",
    "\n",
    "# creating a df with also possible states (including Guam, Virgin Islands, Puerto Rico, American Samoa, and Northern Mariana Islands)\n",
    "# to be joined with states with values\n",
    "all_states = pd.DataFrame(covid_states_df['state'].unique(), columns = ['state'])\n",
    "\n",
    "# merging and formatting\n",
    "full = pd.merge(all_states, w_value, on='state', how='outer')\n",
    "full.sort_values(by='date')[['state', 'date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - DataFrame summarizing  \n",
    "\n",
    "Using **Bloom_etal_2018_Reduced_Dataset.csv**, we are going to do more dataframe manipulation and subsetting and summarizing    \n",
    "\n",
    "### Task 2.1 \n",
    "\n",
    "Read in Bloom_etal_2018_Reduced_Dataset.csv and create two new columns ('genus','species') that consists of the column *taxa* split at the underscore. Print out the head of this new dataframe and the number of unique genera**     \n",
    "\n",
    "*hint:* pd.str.split(,expand=True)  \n",
    "\n",
    "for example:  \n",
    "\n",
    "| taxa | genus | species   \n",
    "| :------ | :-- | :---   \n",
    "| Alosa_alabamae | Alosa | alabamae  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   taxa  logbodysize  trophic_position         Reg  genus  \\\n",
      "0        Alosa_alabamae     1.707570          0.431364  diadromous  Alosa   \n",
      "1           Alosa_alosa     1.778151          0.556303  diadromous  Alosa   \n",
      "2          Alosa_fallax     1.778151          0.556303  diadromous  Alosa   \n",
      "3       Alosa_mediocris     1.778151          0.612784  diadromous  Alosa   \n",
      "4  Alosa_pseudoharengus     1.602060          0.544068  diadromous  Alosa   \n",
      "\n",
      "          species subspecies  \n",
      "0        alabamae       None  \n",
      "1           alosa       None  \n",
      "2          fallax       None  \n",
      "3       mediocris       None  \n",
      "4  pseudoharengus       None   \n",
      "\n",
      "Unique genera = 34\n"
     ]
    }
   ],
   "source": [
    "bloom_species = pd.read_csv(\"Bloom_etal_2018_Reduced_Dataset.csv\")\n",
    "bloom_species[[\"genus\", \"species\", \"subspecies\"]] = bloom_species.taxa.str.split(\"_\", expand=True)\n",
    "print(bloom_species.head(), \"\\n\\nUnique genera =\", bloom_species.genus.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 \n",
    "\n",
    "Create a new dataframe with the mean *logbodysize* and *trophicposition* of each genera. Sort this data frame by the largest body size. Print the head of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_size</th>\n",
       "      <th>avg_trophic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tenualosa</th>\n",
       "      <td>1.778151</td>\n",
       "      <td>0.462398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alosa</th>\n",
       "      <td>1.739062</td>\n",
       "      <td>0.540815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coilia</th>\n",
       "      <td>1.544068</td>\n",
       "      <td>0.477121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethmalosa</th>\n",
       "      <td>1.544068</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Potamalosa</th>\n",
       "      <td>1.505150</td>\n",
       "      <td>0.518514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_size  avg_trophic\n",
       "genus                            \n",
       "Tenualosa   1.778151     0.462398\n",
       "Alosa       1.739062     0.540815\n",
       "Coilia      1.544068     0.477121\n",
       "Ethmalosa   1.544068     0.397940\n",
       "Potamalosa  1.505150     0.518514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_sizes = bloom_species.groupby('genus').agg(avg_size=('logbodysize', 'mean'), avg_trophic=('trophic_position', 'mean')).sort_values(by='avg_size', ascending=False)\n",
    "bloom_sizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which genera is the smallest and largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest genera: Tenualosa\n",
      "Smallest genera: Amazonsprattus\n"
     ]
    }
   ],
   "source": [
    "print(\"Largest genera: %s\\nSmallest genera: %s\" %(bloom_sizes.index[0], bloom_sizes.index[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the trophic position of the smallest and largest?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest genera: Tenualosa (Trophic pos. = 0.46)\n",
      "Smallest genera: Amazonsprattus (Trophic pos. = 0.53)\n"
     ]
    }
   ],
   "source": [
    "print(\"Largest genera: %s (Trophic pos. = %.2f)\\nSmallest genera: %s (Trophic pos. = %.2f)\" %(bloom_sizes.index[0], bloom_sizes.iat[0,1], bloom_sizes.index[-1], bloom_sizes.iat[-1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Read in muliple files to a dictionary and make a DataFrame - **OPTIONAL/BONUS**  \n",
    "\n",
    "### This is not something you are expected to do in this course, but just here to give you an idea of the things that you COULD do. Answers will be posted after due date.  \n",
    "\n",
    "\n",
    "Using **logfiles**: we are going to do read in each file, get some data, append it to a dictionary to later make into a dataframe.     \n",
    "\n",
    "**note:** *make sure to unzip logfiles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Seth/Documents/GitHub/F22_BIOL792_coursepage/week11_python6\n"
     ]
    }
   ],
   "source": [
    "cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tar -xf logfiles.tgz #unzip logfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(PATH,'logfiles')\n",
    "assert os.path.exists(log_dir), 'log_dir does not exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to find the necessary files. The number of files in the log files is 36, make sure you have that many as well  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l logfiles/*txt | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Seth/Documents/GitHub/F22_BIOL792_coursepage/week11_python6/logfiles/1901302108_H7_D_14.txt.txt\n"
     ]
    }
   ],
   "source": [
    "logfiles = !find $log_dir -name '*txt' #unix command to find files in log_dir directory\n",
    "logfiles = [os.path.abspath(x) for x in logfiles] #this finds the full path to the file\n",
    "print(logfiles[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Do not have correct number of logfiles",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(logfiles)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m36\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDo not have correct number of logfiles\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Do not have correct number of logfiles"
     ]
    }
   ],
   "source": [
    "assert(len(logfiles)==36), 'Do not have correct number of logfiles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a little tricky here  \n",
    "\n",
    "Read in each of the logfiles, for each file extract:  \n",
    "- minimum temperature  \n",
    "- maximum temperature  \n",
    "- date of minimum temp   \n",
    "- date of maximum temp   \n",
    "- mean temp for each file.   \n",
    "\n",
    "This data should all be appended for a dictionary within a for loop:    \n",
    "Key should be the file name without the path or .txt extension  \n",
    "Values should be (minTemp,maxTemp,minDate,maxDate,meanTemp)\n",
    "\n",
    "I recommend making this work for one file first, then putting the rest in a for loop to do the rest.  \n",
    "\n",
    "Below is an example of how to read in one file\n",
    "\n",
    "*hint:* do not read date in as date object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 08:00:00</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 08:35:00</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 09:10:00</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 09:45:00</td>\n",
       "      <td>32.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 10:20:00</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 10:55:00</td>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 11:30:00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 12:05:00</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 12:40:00</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 13:15:00</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 13:50:00</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 14:25:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 15:00:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 15:35:00</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 16:10:00</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 16:45:00</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 17:20:00</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 17:55:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 18:30:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 19:05:00</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 19:40:00</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 20:15:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 20:50:00</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 21:25:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 22:00:00</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 22:35:00</td>\n",
       "      <td>33.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 23:10:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013-09-29</td>\n",
       "      <td>2022-11-15 23:45:00</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 00:20:00</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 00:55:00</td>\n",
       "      <td>33.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 01:30:00</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 02:05:00</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 02:40:00</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 03:15:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 03:50:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 04:25:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 05:00:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 05:35:00</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 06:10:00</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>2022-11-15 06:45:00</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                Time  Temp\n",
       "0  2013-09-29 2022-11-15 08:00:00  32.4\n",
       "1  2013-09-29 2022-11-15 08:35:00  32.5\n",
       "2  2013-09-29 2022-11-15 09:10:00  32.5\n",
       "3  2013-09-29 2022-11-15 09:45:00  32.6\n",
       "4  2013-09-29 2022-11-15 10:20:00  32.8\n",
       "5  2013-09-29 2022-11-15 10:55:00  32.9\n",
       "6  2013-09-29 2022-11-15 11:30:00  33.0\n",
       "7  2013-09-29 2022-11-15 12:05:00  33.0\n",
       "8  2013-09-29 2022-11-15 12:40:00  33.2\n",
       "9  2013-09-29 2022-11-15 13:15:00  33.3\n",
       "10 2013-09-29 2022-11-15 13:50:00  33.3\n",
       "11 2013-09-29 2022-11-15 14:25:00  33.4\n",
       "12 2013-09-29 2022-11-15 15:00:00  33.4\n",
       "13 2013-09-29 2022-11-15 15:35:00  33.5\n",
       "14 2013-09-29 2022-11-15 16:10:00  33.6\n",
       "15 2013-09-29 2022-11-15 16:45:00  33.7\n",
       "16 2013-09-29 2022-11-15 17:20:00  33.6\n",
       "17 2013-09-29 2022-11-15 17:55:00  33.8\n",
       "18 2013-09-29 2022-11-15 18:30:00  33.8\n",
       "19 2013-09-29 2022-11-15 19:05:00  33.7\n",
       "20 2013-09-29 2022-11-15 19:40:00  33.7\n",
       "21 2013-09-29 2022-11-15 20:15:00  33.8\n",
       "22 2013-09-29 2022-11-15 20:50:00  33.9\n",
       "23 2013-09-29 2022-11-15 21:25:00  33.8\n",
       "24 2013-09-29 2022-11-15 22:00:00  33.7\n",
       "25 2013-09-29 2022-11-15 22:35:00  33.9\n",
       "26 2013-09-29 2022-11-15 23:10:00  33.8\n",
       "27 2013-09-29 2022-11-15 23:45:00  33.8\n",
       "28 2013-09-30 2022-11-15 00:20:00  33.6\n",
       "29 2013-09-30 2022-11-15 00:55:00  33.6\n",
       "30 2013-09-30 2022-11-15 01:30:00  33.5\n",
       "31 2013-09-30 2022-11-15 02:05:00  33.5\n",
       "32 2013-09-30 2022-11-15 02:40:00  33.5\n",
       "33 2013-09-30 2022-11-15 03:15:00  33.4\n",
       "34 2013-09-30 2022-11-15 03:50:00  33.4\n",
       "35 2013-09-30 2022-11-15 04:25:00  33.4\n",
       "36 2013-09-30 2022-11-15 05:00:00  33.4\n",
       "37 2013-09-30 2022-11-15 05:35:00  33.5\n",
       "38 2013-09-30 2022-11-15 06:10:00  33.4\n",
       "39 2013-09-30 2022-11-15 06:45:00  33.2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### set up data frame as you read in each file\n",
    "infile = pd.read_csv(logfiles[36],sep='\\t',engine='python',encoding='windows-1252',\n",
    "                    parse_dates = ['Date', 'Time'])\n",
    "infile.columns = ['Index','Date','Time','Temp','Type']\n",
    "infile = infile[['Date','Time','Temp']]\n",
    "infile['Date'] = \n",
    "infile.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do everything in steps, make sure it works. Calculate summaries with this one infile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/5/2013'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minTemp =   \n",
    "# maxTemp =  \n",
    "minDate = infile['Date'][infile['Temp'] == infile['Temp'].min()].unique()[0] #use this for minDate \n",
    "maxDate = infile['Date'][infile['Temp'] == infile['Temp'].max()].unique()[0] #use this for maxDate \n",
    "# meanTemp = \n",
    "minDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get you started, I suggest writing some dummy code in plain words to help outline your for loop:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfiles_dict = {}  \n",
    "for f in logfiles:  \n",
    "    #do something   \n",
    "    #do not read date in as date object  \n",
    "    #do more something   \n",
    "    #do other stuff  \n",
    "    #make print statements EVERYWHERE  \n",
    "    #append to dict  \n",
    "    #blahbahblah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do the real code below here. You don't need to turnin your thoughts. Just put it in there as a help reminder. Most people all still do this, no matter how advanced they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you have created a DataFrame with all the logfiles, print the head and save it to an outfile using pd.to_csv() as logfiles_df.csv** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is an example of the final product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logfiles_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogfiles_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logfiles_df' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
